{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T14:25:16.616041Z",
     "start_time": "2024-03-10T14:25:16.582739Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<duckdb.duckdb.DuckDBPyConnection at 0x10491c8f0>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import duckdb\n",
    "\n",
    "# some DuckDB setup\n",
    "con = duckdb.connect(database=':memory:')\n",
    "# enable automatic query parallelization\n",
    "con.execute(\"PRAGMA threads=2\")\n",
    "# enable caching of parquet metadata\n",
    "con.execute(\"PRAGMA enable_object_cache\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data = \"'../data/train-[1-8].parquet'\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T14:25:44.698458Z",
     "start_time": "2024-03-10T14:25:44.696526Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Create train and test split from the beginning for comparability"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "film_ids = con.execute(f\"\"\"\n",
    "    select distinct tconst,\n",
    "        label\n",
    "    from {train_data}\n",
    "    \"\"\").df()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T15:25:50.768337Z",
     "start_time": "2024-03-10T15:25:50.757964Z"
    }
   },
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split training data in train and test split\n",
    "\n",
    "ids = film_ids.drop('label', axis=1).values\n",
    "labels = film_ids.loc[:, 'label'].values\n",
    "\n",
    "# Small test size because cross-validation (and want to train on more data)\n",
    "X_train_ids, X_test_ids, y_train, y_test = train_test_split(ids, labels, test_size=0.10, random_state=42, stratify=labels)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T15:25:51.218358Z",
     "start_time": "2024-03-10T15:25:51.213221Z"
    }
   },
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X_train_ids  = pd.DataFrame(X_train_ids, columns=['tconst'])\n",
    "X_test_ids = pd.DataFrame(X_test_ids, columns=['label'])\n",
    "\n",
    "X_train_ids.to_parquet(\"X_train_ids.parquet\")\n",
    "X_test_ids.to_parquet(\"X_test_ids.parquet\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T15:25:51.991284Z",
     "start_time": "2024-03-10T15:25:51.984506Z"
    }
   },
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ids_train = \"'X_train_ids.parquet'\"\n",
    "ids_test = \"'X_test_ids.parquet'\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T15:48:26.918272Z",
     "start_time": "2024-03-10T15:48:26.916678Z"
    }
   },
   "execution_count": 56
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Establish Baseline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T16:09:40.095889Z",
     "start_time": "2024-03-10T16:09:40.091399Z"
    }
   },
   "execution_count": 94
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset as it is\n",
    "\n",
    "Dropping NaN in train set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load all the data into the duck database\n",
    "baseline_data_train = con.execute(f\"\"\"\n",
    "    with train as (\n",
    "        select * \n",
    "        from {train_data}\n",
    "    )\n",
    " select tconst, \n",
    "        try_cast(startYear as integer) as year,\n",
    "        try_cast(runtimeMinutes as integer) as runtime, \n",
    "        try_cast(numVotes as integer) as votes,\n",
    "        CASE\n",
    "           WHEN originalTitle IS NULL THEN 0\n",
    "           ELSE 1\n",
    "        END AS ForeignFilm,\n",
    "        -- Count number of words in title\n",
    "        LENGTH(primaryTitle) - LENGTH(REPLACE(primaryTitle, ' ', '')) + 1 AS n_words,\n",
    "        label\n",
    "    from train\n",
    "    where train.tconst in (select tconst from {ids_train})\n",
    "\n",
    "\"\"\").df()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T16:03:14.610706Z",
     "start_time": "2024-03-10T16:03:14.593150Z"
    }
   },
   "execution_count": 87
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load all the data into the duck database\n",
    "baseline_data_test = con.execute(f\"\"\"\n",
    "    with train as (\n",
    "        select * \n",
    "        from {train_data}\n",
    "    )\n",
    "    select tconst, \n",
    "        try_cast(startYear as integer) as year,\n",
    "        try_cast(runtimeMinutes as integer) as runtime, \n",
    "        try_cast(numVotes as integer) as votes,\n",
    "        CASE\n",
    "           WHEN originalTitle IS NULL THEN 0\n",
    "           ELSE 1\n",
    "        END AS ForeignFilm,\n",
    "        -- Count number of words in title\n",
    "        LENGTH(primaryTitle) - LENGTH(REPLACE(primaryTitle, ' ', '')) + 1 AS n_words,\n",
    "        label\n",
    "    from train\n",
    "    where train.tconst in (select tconst from {ids_test})\n",
    "\n",
    "\"\"\").df()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T16:03:21.354406Z",
     "start_time": "2024-03-10T16:03:20.884988Z"
    }
   },
   "execution_count": 88
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "baseline_data_train_noNAN = baseline_data_train.dropna()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T16:10:23.744277Z",
     "start_time": "2024-03-10T16:10:23.739657Z"
    }
   },
   "execution_count": 95
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_train = baseline_data_train_noNAN.drop(['tconst',  'label'], axis=1).values\n",
    "y_train = baseline_data_train.loc[:, 'label'].values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T16:10:29.154744Z",
     "start_time": "2024-03-10T16:10:29.149936Z"
    }
   },
   "execution_count": 96
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_test = baseline_data_test.drop(['tconst',  'label'], axis=1).values\n",
    "y_test = baseline_data_test.loc[:, 'label'].values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T16:10:29.540461Z",
     "start_time": "2024-03-10T16:10:29.537439Z"
    }
   },
   "execution_count": 97
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "RandomForest best parameters: {'classifier__max_depth': 10, 'classifier__n_estimators': 150}\n",
      "RandomForest best score: 0.7367\n",
      "Accuracy: 79.09% 78.16%\n",
      "Confusion Matrix:\n",
      "[[3322  647]\n",
      " [1017 2973]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.77      0.84      0.80      3969\n",
      "        True       0.82      0.75      0.78      3990\n",
      "\n",
      "    accuracy                           0.79      7959\n",
      "   macro avg       0.79      0.79      0.79      7959\n",
      "weighted avg       0.79      0.79      0.79      7959\n",
      "\n",
      "0.5060220233998624 0.5013192612137203 0.4548310089207187 0.43257028107990225\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing pipeline\n",
    "preprocessing = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "# Base model pipelines\n",
    "models = {\n",
    "    'RandomForest': Pipeline(steps=[('preprocessing', preprocessing), ('classifier', RandomForestClassifier())])\n",
    "}\n",
    "\n",
    "hyperparameters = {\n",
    "    'RandomForest': {\n",
    "        'classifier__n_estimators': [50, 100, 150, 200],\n",
    "        'classifier__max_depth': [1, 3, 5, 7, 10],\n",
    "    }\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "for model_name, model_pipeline in models.items():\n",
    "    # Create a GridSearchCV object\n",
    "    grid_search = GridSearchCV(model_pipeline, hyperparameters[model_name], cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "    # Fit the model\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Store the best model\n",
    "    best_models[model_name] = grid_search.best_estimator_\n",
    "\n",
    "    # Print the best parameters and the best score\n",
    "    print(f\"{model_name} best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"{model_name} best score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "    # Use the best estimator to make predictions\n",
    "    y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "    # Test if adjusting the threshold helps improve the accuracy (knowing dataset is balanced)\n",
    "    y_proba = grid_search.best_estimator_.predict_proba(X_test)[:,1]\n",
    "    threshold = np.median(y_proba)\n",
    "    y_pred_th = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    # Calculate and print the accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}% {accuracy_score(y_test, y_pred_th) * 100:.2f}%\")\n",
    "\n",
    "    # Print the confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "    # Print the classification report\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    print(\"Classification Report:\")\n",
    "    print(class_report)\n",
    "\n",
    "    # See how balanced the predictions are\n",
    "    print (y_train.mean(), y_test.mean(), y_pred.mean(), threshold)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T16:10:36.149350Z",
     "start_time": "2024-03-10T16:10:29.784543Z"
    }
   },
   "execution_count": 98
  },
  {
   "cell_type": "markdown",
   "source": [
    "Keeping NaN and replacing and imputing them"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_train = baseline_data_train.drop(['tconst',  'label'], axis=1).values\n",
    "y_train = baseline_data_train.loc[:, 'label'].values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T16:10:38.631198Z",
     "start_time": "2024-03-10T16:10:38.627944Z"
    }
   },
   "execution_count": 100
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_test = baseline_data_test.drop(['tconst',  'label'], axis=1).values\n",
    "y_test = baseline_data_test.loc[:, 'label'].values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T16:10:38.824278Z",
     "start_time": "2024-03-10T16:10:38.820993Z"
    }
   },
   "execution_count": 101
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "RandomForest best parameters: {'classifier__max_depth': 10, 'classifier__n_estimators': 200}\n",
      "RandomForest best score: 0.7244\n",
      "Accuracy: 79.51% 78.49%\n",
      "Confusion Matrix:\n",
      "[[3424  545]\n",
      " [1086 2904]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.76      0.86      0.81      3969\n",
      "        True       0.84      0.73      0.78      3990\n",
      "\n",
      "    accuracy                           0.80      7959\n",
      "   macro avg       0.80      0.80      0.79      7959\n",
      "weighted avg       0.80      0.80      0.79      7959\n",
      "\n",
      "0.5013262599469496 0.5013192612137203 0.433345897725845 0.41678257671050867\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing pipeline\n",
    "preprocessing = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "# Base model pipelines\n",
    "models = {\n",
    "    'RandomForest': Pipeline(steps=[('preprocessing', preprocessing), ('classifier', RandomForestClassifier())])\n",
    "}\n",
    "\n",
    "hyperparameters = {\n",
    "    'RandomForest': {\n",
    "        'classifier__n_estimators': [50, 100, 150, 200],\n",
    "        'classifier__max_depth': [1, 3, 5, 7, 10],\n",
    "    }\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "for model_name, model_pipeline in models.items():\n",
    "    # Create a GridSearchCV object\n",
    "    grid_search = GridSearchCV(model_pipeline, hyperparameters[model_name], cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "    # Fit the model\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Store the best model\n",
    "    best_models[model_name] = grid_search.best_estimator_\n",
    "\n",
    "    # Print the best parameters and the best score\n",
    "    print(f\"{model_name} best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"{model_name} best score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "    # Use the best estimator to make predictions\n",
    "    y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "    # Test if adjusting the threshold helps improve the accuracy (knowing dataset is balanced)\n",
    "    y_proba = grid_search.best_estimator_.predict_proba(X_test)[:,1]\n",
    "    threshold = np.median(y_proba)\n",
    "    y_pred_th = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    # Calculate and print the accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}% {accuracy_score(y_test, y_pred_th) * 100:.2f}%\")\n",
    "\n",
    "    # Print the confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "    # Print the classification report\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    print(\"Classification Report:\")\n",
    "    print(class_report)\n",
    "\n",
    "    # See how balanced the predictions are\n",
    "    print (y_train.mean(), y_test.mean(), y_pred.mean(), threshold)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T16:10:44.783307Z",
     "start_time": "2024-03-10T16:10:38.999119Z"
    }
   },
   "execution_count": 102
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fixing the year issue"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load all the data into the duck database\n",
    "train_fixed_year = con.execute(f\"\"\"\n",
    "    with train as (\n",
    "        select * \n",
    "        from {train_data}\n",
    "    )\n",
    " select tconst, \n",
    "        -- Merge start year and end year into single column\n",
    "        CASE\n",
    "            WHEN startYear LIKE '%N%' THEN endYear\n",
    "            ELSE startYear\n",
    "        END AS year,\n",
    "        try_cast(runtimeMinutes as integer) as runtime, \n",
    "        try_cast(numVotes as integer) as votes,\n",
    "        CASE\n",
    "           WHEN originalTitle IS NULL THEN 0\n",
    "           ELSE 1\n",
    "        END AS ForeignFilm,\n",
    "        -- Count number of words in title\n",
    "        LENGTH(primaryTitle) - LENGTH(REPLACE(primaryTitle, ' ', '')) + 1 AS n_words,\n",
    "        label\n",
    "    from train\n",
    "    where train.tconst in (select tconst from {ids_train})\n",
    "\n",
    "\"\"\").df()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T16:19:46.946058Z",
     "start_time": "2024-03-10T16:19:46.926857Z"
    }
   },
   "execution_count": 105
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load all the data into the duck database\n",
    "test_fixed_year = con.execute(f\"\"\"\n",
    "    with train as (\n",
    "        select * \n",
    "        from {train_data}\n",
    "    )\n",
    "    select tconst, \n",
    "        -- Merge start year and end year into single column\n",
    "        CASE\n",
    "            WHEN startYear LIKE '%N%' THEN endYear\n",
    "            ELSE startYear\n",
    "        END AS year,\n",
    "        try_cast(runtimeMinutes as integer) as runtime, \n",
    "        try_cast(numVotes as integer) as votes,\n",
    "        CASE\n",
    "           WHEN originalTitle IS NULL THEN 0\n",
    "           ELSE 1\n",
    "        END AS ForeignFilm,\n",
    "        -- Count number of words in title\n",
    "        LENGTH(primaryTitle) - LENGTH(REPLACE(primaryTitle, ' ', '')) + 1 AS n_words,\n",
    "        label\n",
    "    from train\n",
    "    where train.tconst in (select tconst from {ids_test})\n",
    "\n",
    "\"\"\").df()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T16:19:44.875194Z",
     "start_time": "2024-03-10T16:19:44.380784Z"
    }
   },
   "execution_count": 104
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_train = train_fixed_year.drop(['tconst',  'label'], axis=1).values\n",
    "y_train = train_fixed_year.loc[:, 'label'].values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T16:20:05.770178Z",
     "start_time": "2024-03-10T16:20:05.764905Z"
    }
   },
   "execution_count": 106
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_test = test_fixed_year.drop(['tconst',  'label'], axis=1).values\n",
    "y_test = test_fixed_year.loc[:, 'label'].values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T16:20:05.928814Z",
     "start_time": "2024-03-10T16:20:05.925256Z"
    }
   },
   "execution_count": 107
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "RandomForest best parameters: {'classifier__max_depth': 10, 'classifier__n_estimators': 100}\n",
      "RandomForest best score: 0.7283\n",
      "Accuracy: 80.37% 79.47%\n",
      "Confusion Matrix:\n",
      "[[3462  507]\n",
      " [1055 2935]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.77      0.87      0.82      3969\n",
      "        True       0.85      0.74      0.79      3990\n",
      "\n",
      "    accuracy                           0.80      7959\n",
      "   macro avg       0.81      0.80      0.80      7959\n",
      "weighted avg       0.81      0.80      0.80      7959\n",
      "\n",
      "0.5013262599469496 0.5013192612137203 0.4324663902500314 0.4144205803399021\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing pipeline\n",
    "preprocessing = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "# Base model pipelines\n",
    "models = {\n",
    "    'RandomForest': Pipeline(steps=[('preprocessing', preprocessing), ('classifier', RandomForestClassifier())])\n",
    "}\n",
    "\n",
    "hyperparameters = {\n",
    "    'RandomForest': {\n",
    "        'classifier__n_estimators': [50, 100, 150, 200],\n",
    "        'classifier__max_depth': [1, 3, 5, 7, 10],\n",
    "    }\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "for model_name, model_pipeline in models.items():\n",
    "    # Create a GridSearchCV object\n",
    "    grid_search = GridSearchCV(model_pipeline, hyperparameters[model_name], cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "    # Fit the model\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Store the best model\n",
    "    best_models[model_name] = grid_search.best_estimator_\n",
    "\n",
    "    # Print the best parameters and the best score\n",
    "    print(f\"{model_name} best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"{model_name} best score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "    # Use the best estimator to make predictions\n",
    "    y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "    # Test if adjusting the threshold helps improve the accuracy (knowing dataset is balanced)\n",
    "    y_proba = grid_search.best_estimator_.predict_proba(X_test)[:,1]\n",
    "    threshold = np.median(y_proba)\n",
    "    y_pred_th = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    # Calculate and print the accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}% {accuracy_score(y_test, y_pred_th) * 100:.2f}%\")\n",
    "\n",
    "    # Print the confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "    # Print the classification report\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    print(\"Classification Report:\")\n",
    "    print(class_report)\n",
    "\n",
    "    # See how balanced the predictions are\n",
    "    print (y_train.mean(), y_test.mean(), y_pred.mean(), threshold)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T16:20:21.824575Z",
     "start_time": "2024-03-10T16:20:15.296723Z"
    }
   },
   "execution_count": 108
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Adding additional features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "         tconst  Year\n0     tt0003740  1914\n1     tt0008663  1917\n2     tt0009369  1918\n3     tt0010307  1919\n4     tt0010600  1919\n...         ...   ...\n9995  tt9766294  2021\n9996  tt9769668  2021\n9997  tt9784798  2021\n9998  tt9808510  2021\n9999  tt9849004  2021\n\n[10000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tconst</th>\n      <th>Year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tt0003740</td>\n      <td>1914</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>tt0008663</td>\n      <td>1917</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>tt0009369</td>\n      <td>1918</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>tt0010307</td>\n      <td>1919</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>tt0010600</td>\n      <td>1919</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>tt9766294</td>\n      <td>2021</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>tt9769668</td>\n      <td>2021</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>tt9784798</td>\n      <td>2021</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>tt9808510</td>\n      <td>2021</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>tt9849004</td>\n      <td>2021</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all films listed in the writer/director files with the year of the film \n",
    "# (from training, validation and test data).\n",
    "movie_year = con.execute('''\n",
    "    SELECT tconst,\n",
    "        CASE\n",
    "            WHEN startYear LIKE '%N%' THEN endYear\n",
    "            ELSE startYear\n",
    "        END AS Year,\n",
    "    FROM '../data/train-[1-8].parquet'\n",
    "    UNION\n",
    "    SELECT tconst,\n",
    "        CASE\n",
    "            WHEN startYear LIKE '%N%' THEN endYear\n",
    "            ELSE startYear\n",
    "        END AS Year,\n",
    "    FROM '../data/test_hidden.parquet'\n",
    "    UNION\n",
    "    SELECT tconst,\n",
    "        CASE\n",
    "            WHEN startYear LIKE '%N%' THEN endYear\n",
    "            ELSE startYear\n",
    "        END AS Year,\n",
    "    FROM '../data/validation_hidden.parquet'\n",
    "    ORDER BY Year, tconst\n",
    "''').df()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T16:23:16.911981Z",
     "start_time": "2024-03-10T16:23:16.897277Z"
    }
   },
   "execution_count": 114
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "          tconst  Year      writer   director  writer_experience  \\\n0      tt0003740  1914   nm0195339  nm0665163                  1   \n1      tt0003740  1914   nm0665163  nm0665163                  1   \n2      tt0003740  1914   nm0758215  nm0665163                  1   \n3      tt0003740  1914   nm0515385  nm0665163                  1   \n4      tt0008663  1917   nm0803705  nm0803705                  1   \n...          ...   ...         ...        ...                ...   \n27883  tt9784798  2021   nm0077768  nm3489851                  1   \n27884  tt9808510  2021   nm9925241  nm8904180                  1   \n27885  tt9808510  2021   nm8904180  nm8904180                  1   \n27886  tt9808510  2021  nm10260663  nm8904180                  1   \n27887  tt9849004  2021   nm2818863  nm2818863                  2   \n\n       director_experience  \n0                        1  \n1                        1  \n2                        1  \n3                        1  \n4                        1  \n...                    ...  \n27883                    1  \n27884                    1  \n27885                    1  \n27886                    1  \n27887                    1  \n\n[27888 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tconst</th>\n      <th>Year</th>\n      <th>writer</th>\n      <th>director</th>\n      <th>writer_experience</th>\n      <th>director_experience</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tt0003740</td>\n      <td>1914</td>\n      <td>nm0195339</td>\n      <td>nm0665163</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>tt0003740</td>\n      <td>1914</td>\n      <td>nm0665163</td>\n      <td>nm0665163</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>tt0003740</td>\n      <td>1914</td>\n      <td>nm0758215</td>\n      <td>nm0665163</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>tt0003740</td>\n      <td>1914</td>\n      <td>nm0515385</td>\n      <td>nm0665163</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>tt0008663</td>\n      <td>1917</td>\n      <td>nm0803705</td>\n      <td>nm0803705</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>27883</th>\n      <td>tt9784798</td>\n      <td>2021</td>\n      <td>nm0077768</td>\n      <td>nm3489851</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>27884</th>\n      <td>tt9808510</td>\n      <td>2021</td>\n      <td>nm9925241</td>\n      <td>nm8904180</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>27885</th>\n      <td>tt9808510</td>\n      <td>2021</td>\n      <td>nm8904180</td>\n      <td>nm8904180</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>27886</th>\n      <td>tt9808510</td>\n      <td>2021</td>\n      <td>nm10260663</td>\n      <td>nm8904180</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>27887</th>\n      <td>tt9849004</td>\n      <td>2021</td>\n      <td>nm2818863</td>\n      <td>nm2818863</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>27888 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the number of films worked on previously by the writers and directors\n",
    "# Includes the current film\n",
    "\n",
    "experience = con.execute('''\n",
    "    with writers as (\n",
    "        select *\n",
    "        from '../data/writing.parquet'\n",
    "    ), \n",
    "    directors as (\n",
    "        select * \n",
    "        from '../data/directing.parquet'\n",
    "    \n",
    "    )\n",
    "    SELECT tconst, Year, writer, director,\n",
    "    COUNT(DISTINCT tconst) OVER(PARTITION BY writer ORDER BY Year, tconst) AS writer_experience,\n",
    "    COUNT(DISTINCT tconst) OVER(PARTITION BY director ORDER BY Year, tconst) AS director_experience,\n",
    "    FROM movie_year my\n",
    "    LEFT JOIN writers ON writers.movie == my.tconst\n",
    "    LEFT JOIN directors ON directors.movie == my.tconst\n",
    "    ORDER BY Year, tconst\n",
    "''').df()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T16:25:17.550233Z",
     "start_time": "2024-03-10T16:25:17.502943Z"
    }
   },
   "execution_count": 116
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load all the data into the duck database\n",
    "train_features = con.execute(f\"\"\"\n",
    "    with train as (\n",
    "        select * \n",
    "        from {train_data}\n",
    "    )\n",
    " select tconst, \n",
    "        -- Merge start year and end year into single column\n",
    "        CASE\n",
    "            WHEN startYear LIKE '%N%' THEN endYear\n",
    "            ELSE startYear\n",
    "        END AS year,\n",
    "        try_cast(runtimeMinutes as integer) as runtime, \n",
    "        try_cast(numVotes as integer) as votes,\n",
    "        CASE\n",
    "           WHEN originalTitle IS NULL THEN 0\n",
    "           ELSE 1\n",
    "        END AS ForeignFilm,\n",
    "        -- Count number of words in title\n",
    "        LENGTH(primaryTitle) - LENGTH(REPLACE(primaryTitle, ' ', '')) + 1 AS n_words,\n",
    "        label\n",
    "    from train\n",
    "    where train.tconst in (select tconst from {ids_train})\n",
    "\n",
    "\"\"\").df()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T19:59:51.816068Z",
     "start_time": "2024-03-10T19:59:51.797323Z"
    }
   },
   "execution_count": 123
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load all the data into the duck database\n",
    "test_features = con.execute(f\"\"\"\n",
    "    with train as (\n",
    "        select * \n",
    "        from {train_data}\n",
    "    )\n",
    "    select tconst, \n",
    "        -- Merge start year and end year into single column\n",
    "        CASE\n",
    "            WHEN startYear LIKE '%N%' THEN endYear\n",
    "            ELSE startYear\n",
    "        END AS year,\n",
    "        try_cast(runtimeMinutes as integer) as runtime, \n",
    "        try_cast(numVotes as integer) as votes,\n",
    "        CASE\n",
    "           WHEN originalTitle IS NULL THEN 0\n",
    "           ELSE 1\n",
    "        END AS ForeignFilm,\n",
    "        -- Count number of words in title\n",
    "        LENGTH(primaryTitle) - LENGTH(REPLACE(primaryTitle, ' ', '')) + 1 AS n_words,\n",
    "        label\n",
    "    from train\n",
    "    where train.tconst in (select tconst from {ids_test})\n",
    "\n",
    "\"\"\").df()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T19:59:52.392992Z",
     "start_time": "2024-03-10T19:59:51.995026Z"
    }
   },
   "execution_count": 124
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Merge movie data with the experience level of the writers and directors.\n",
    "# For each film, calculate the number of writers/directors, average experience and total experience\n",
    "\n",
    "train_all_features = con.execute('''\n",
    "    SELECT \n",
    "      ANY_VALUE(td.tconst) AS tconst, \n",
    "      ANY_VALUE(td.Year) AS Year, \n",
    "      ANY_VALUE(runtime) AS runtimeMinutes,\n",
    "      ANY_VALUE(ForeignFilm) AS ForeignFilm, \n",
    "      ANY_VALUE(n_words) AS n_words, \n",
    "      ANY_VALUE(votes) AS numVotes,\n",
    "      COUNT(DISTINCT writer) AS n_writers,\n",
    "      AVG(DISTINCT e.writer_experience) AS avgexp_writers,\n",
    "      SUM(DISTINCT e.writer_experience) AS totexp_writers,\n",
    "      COUNT(DISTINCT director) AS n_directors,\n",
    "      AVG(DISTINCT e.director_experience) AS avgexp_directors,\n",
    "      SUM(DISTINCT e.director_experience) AS totexp_directors,\n",
    "      ANY_VALUE(label) AS label\n",
    "    FROM train_features td\n",
    "    LEFT JOIN experience e ON e.tconst == td.tconst\n",
    "    GROUP BY td.tconst\n",
    "''').df()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T20:08:43.691394Z",
     "start_time": "2024-03-10T20:08:43.668229Z"
    }
   },
   "execution_count": 130
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Merge movie data with the experience level of the writers and directors.\n",
    "# For each film, calculate the number of writers/directors, average experience and total experience\n",
    "\n",
    "test_all_features = con.execute('''\n",
    "    SELECT \n",
    "      ANY_VALUE(td.tconst) AS tconst, \n",
    "      ANY_VALUE(td.Year) AS Year, \n",
    "      ANY_VALUE(runtime) AS runtimeMinutes,\n",
    "      ANY_VALUE(ForeignFilm) AS ForeignFilm, \n",
    "      ANY_VALUE(n_words) AS n_words, \n",
    "      ANY_VALUE(votes) AS numVotes,\n",
    "      COUNT(DISTINCT writer) AS n_writers,\n",
    "      AVG(DISTINCT e.writer_experience) AS avgexp_writers,\n",
    "      SUM(DISTINCT e.writer_experience) AS totexp_writers,\n",
    "      COUNT(DISTINCT director) AS n_directors,\n",
    "      AVG(DISTINCT e.director_experience) AS avgexp_directors,\n",
    "      SUM(DISTINCT e.director_experience) AS totexp_directors,\n",
    "      ANY_VALUE(label) AS label\n",
    "    FROM test_features td\n",
    "    LEFT JOIN experience e ON e.tconst == td.tconst\n",
    "    GROUP BY td.tconst\n",
    "''').df()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T20:08:44.052947Z",
     "start_time": "2024-03-10T20:08:44.033093Z"
    }
   },
   "execution_count": 131
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_train = train_all_features.drop(['tconst',  'label'], axis=1).values\n",
    "y_train = train_all_features.loc[:, 'label'].values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T20:09:23.855323Z",
     "start_time": "2024-03-10T20:09:23.849575Z"
    }
   },
   "execution_count": 135
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_test = test_all_features.drop(['tconst',  'label'], axis=1).values\n",
    "y_test = test_all_features.loc[:, 'label'].values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T20:09:24.235865Z",
     "start_time": "2024-03-10T20:09:24.231759Z"
    }
   },
   "execution_count": 136
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "RandomForest best parameters: {'classifier__max_depth': 10, 'classifier__n_estimators': 200}\n",
      "RandomForest best score: 0.7190\n",
      "Accuracy: 81.38% 80.58%\n",
      "Confusion Matrix:\n",
      "[[3473  496]\n",
      " [ 986 3004]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.78      0.88      0.82      3969\n",
      "        True       0.86      0.75      0.80      3990\n",
      "\n",
      "    accuracy                           0.81      7959\n",
      "   macro avg       0.82      0.81      0.81      7959\n",
      "weighted avg       0.82      0.81      0.81      7959\n",
      "\n",
      "0.5013262599469496 0.5013192612137203 0.4397537379067722 0.4174755437366656\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing pipeline\n",
    "preprocessing = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "# Base model pipelines\n",
    "models = {\n",
    "    'RandomForest': Pipeline(steps=[('preprocessing', preprocessing), ('classifier', RandomForestClassifier())])\n",
    "}\n",
    "\n",
    "hyperparameters = {\n",
    "    'RandomForest': {\n",
    "        'classifier__n_estimators': [50, 100, 150, 200],\n",
    "        'classifier__max_depth': [1, 3, 5, 7, 10],\n",
    "    }\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "for model_name, model_pipeline in models.items():\n",
    "    # Create a GridSearchCV object\n",
    "    grid_search = GridSearchCV(model_pipeline, hyperparameters[model_name], cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "    # Fit the model\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Store the best model\n",
    "    best_models[model_name] = grid_search.best_estimator_\n",
    "\n",
    "    # Print the best parameters and the best score\n",
    "    print(f\"{model_name} best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"{model_name} best score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "    # Use the best estimator to make predictions\n",
    "    y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "    # Test if adjusting the threshold helps improve the accuracy (knowing dataset is balanced)\n",
    "    y_proba = grid_search.best_estimator_.predict_proba(X_test)[:,1]\n",
    "    threshold = np.median(y_proba)\n",
    "    y_pred_th = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    # Calculate and print the accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}% {accuracy_score(y_test, y_pred_th) * 100:.2f}%\")\n",
    "\n",
    "    # Print the confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "    # Print the classification report\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    print(\"Classification Report:\")\n",
    "    print(class_report)\n",
    "\n",
    "    # See how balanced the predictions are\n",
    "    print (y_train.mean(), y_test.mean(), y_pred.mean(), threshold)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T20:09:32.776254Z",
     "start_time": "2024-03-10T20:09:25.700498Z"
    }
   },
   "execution_count": 137
  },
  {
   "cell_type": "markdown",
   "source": [
    "**All features**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load all the data into the duck database\n",
    "train_features = con.execute(f\"\"\"\n",
    "    with train as (\n",
    "        select * \n",
    "        from {train_data}\n",
    "    )\n",
    " select tconst, \n",
    "    -- Clean up the movie title text. Remove excess whitespace, convert to lowercase, convert non-ascii to ascii equivalent, \n",
    "        -- remove everything that is non-alpanumeric or a space.\n",
    "        REGEXP_REPLACE(TRANSLATE(LOWER(TRIM(primaryTitle)), 'áàãäåæßçéèêíîïñòóôöøớúûüý','aaaaaabceeeiiinoooooouuuy'),'[^a-zA-Z0-9 ]','','g') AS pTitle,\n",
    "        REGEXP_REPLACE(TRANSLATE(LOWER(TRIM(originalTitle)),'áàãäåæßçéèêíîïñòóôöøớúûüý','aaaaaabceeeiiinoooooouuuy'),'[^a-zA-Z0-9 ]','','g') AS oTitle,\n",
    "        \n",
    "        -- Merge start year and end year into single column\n",
    "        CASE\n",
    "            WHEN startYear LIKE '%N%' THEN endYear\n",
    "            ELSE startYear\n",
    "        END AS year,\n",
    "        try_cast(runtimeMinutes as integer) as runtime, \n",
    "        try_cast(numVotes as integer) as votes,\n",
    "        CASE\n",
    "           WHEN originalTitle IS NULL THEN 0\n",
    "           ELSE 1\n",
    "        END AS ForeignFilm,\n",
    "        -- Count number of words in title\n",
    "        LENGTH(primaryTitle) - LENGTH(REPLACE(primaryTitle, ' ', '')) + 1 AS n_words,\n",
    "        label\n",
    "    from train\n",
    "    where train.tconst in (select tconst from {ids_train})\n",
    "\n",
    "\"\"\").df()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T20:12:16.722407Z",
     "start_time": "2024-03-10T20:12:16.690103Z"
    }
   },
   "execution_count": 138
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load all the data into the duck database\n",
    "test_features = con.execute(f\"\"\"\n",
    "    with train as (\n",
    "        select * \n",
    "        from {train_data}\n",
    "    )\n",
    "    select tconst, \n",
    "       -- Clean up the movie title text. Remove excess whitespace, convert to lowercase, convert non-ascii to ascii equivalent, \n",
    "        -- remove everything that is non-alpanumeric or a space.\n",
    "        REGEXP_REPLACE(TRANSLATE(LOWER(TRIM(primaryTitle)), 'áàãäåæßçéèêíîïñòóôöøớúûüý','aaaaaabceeeiiinoooooouuuy'),'[^a-zA-Z0-9 ]','','g') AS pTitle,\n",
    "        REGEXP_REPLACE(TRANSLATE(LOWER(TRIM(originalTitle)),'áàãäåæßçéèêíîïñòóôöøớúûüý','aaaaaabceeeiiinoooooouuuy'),'[^a-zA-Z0-9 ]','','g') AS oTitle,\n",
    "        \n",
    "        -- Merge start year and end year into single column\n",
    "        CASE\n",
    "            WHEN startYear LIKE '%N%' THEN endYear\n",
    "            ELSE startYear\n",
    "        END AS year,\n",
    "        try_cast(runtimeMinutes as integer) as runtime, \n",
    "        try_cast(numVotes as integer) as votes,\n",
    "        CASE\n",
    "           WHEN originalTitle IS NULL THEN 0\n",
    "           ELSE 1\n",
    "        END AS ForeignFilm,\n",
    "        -- Count number of words in title\n",
    "        LENGTH(primaryTitle) - LENGTH(REPLACE(primaryTitle, ' ', '')) + 1 AS n_words,\n",
    "        label\n",
    "    from train\n",
    "    where train.tconst in (select tconst from {ids_test})\n",
    "\n",
    "\"\"\").df()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T20:12:17.399963Z",
     "start_time": "2024-03-10T20:12:16.870696Z"
    }
   },
   "execution_count": 139
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Merge movie data with the experience level of the writers and directors.\n",
    "# For each film, calculate the number of writers/directors, average experience and total experience\n",
    "\n",
    "train_fixed_title = con.execute('''\n",
    "    SELECT \n",
    "    \n",
    "      ANY_VALUE(td.tconst) AS tconst, \n",
    "      ANY_VALUE(td.Year) AS Year, \n",
    "      ANY_VALUE(runtime) AS runtimeMinutes,\n",
    "      ANY_VALUE(ForeignFilm) AS ForeignFilm, \n",
    "      ANY_VALUE(n_words) AS n_words, \n",
    "      ANY_VALUE(votes) AS numVotes,\n",
    "      COUNT(DISTINCT writer) AS n_writers,\n",
    "      AVG(DISTINCT e.writer_experience) AS avgexp_writers,\n",
    "      SUM(DISTINCT e.writer_experience) AS totexp_writers,\n",
    "      COUNT(DISTINCT director) AS n_directors,\n",
    "      AVG(DISTINCT e.director_experience) AS avgexp_directors,\n",
    "      SUM(DISTINCT e.director_experience) AS totexp_directors,\n",
    "      ANY_VALUE(label) AS label\n",
    "    FROM train_features td\n",
    "    LEFT JOIN experience e ON e.tconst == td.tconst\n",
    "    GROUP BY td.tconst\n",
    "''').df()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T20:12:30.664289Z",
     "start_time": "2024-03-10T20:12:30.639923Z"
    }
   },
   "execution_count": 140
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Merge movie data with the experience level of the writers and directors.\n",
    "# For each film, calculate the number of writers/directors, average experience and total experience\n",
    "\n",
    "test_fixed_title = con.execute('''\n",
    "    SELECT \n",
    "      ANY_VALUE(td.tconst) AS tconst, \n",
    "      ANY_VALUE(td.Year) AS Year, \n",
    "      ANY_VALUE(runtime) AS runtimeMinutes,\n",
    "      ANY_VALUE(ForeignFilm) AS ForeignFilm, \n",
    "      ANY_VALUE(n_words) AS n_words, \n",
    "      ANY_VALUE(votes) AS numVotes,\n",
    "      COUNT(DISTINCT writer) AS n_writers,\n",
    "      AVG(DISTINCT e.writer_experience) AS avgexp_writers,\n",
    "      SUM(DISTINCT e.writer_experience) AS totexp_writers,\n",
    "      COUNT(DISTINCT director) AS n_directors,\n",
    "      AVG(DISTINCT e.director_experience) AS avgexp_directors,\n",
    "      SUM(DISTINCT e.director_experience) AS totexp_directors,\n",
    "      ANY_VALUE(label) AS label\n",
    "    FROM test_features td\n",
    "    LEFT JOIN experience e ON e.tconst == td.tconst\n",
    "    GROUP BY td.tconst\n",
    "''').df()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T20:12:41.570751Z",
     "start_time": "2024-03-10T20:12:41.549868Z"
    }
   },
   "execution_count": 141
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_train = train_fixed_title.drop(['tconst',  'label'], axis=1).values\n",
    "y_train = train_fixed_title.loc[:, 'label'].values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T20:13:14.079571Z",
     "start_time": "2024-03-10T20:13:14.074801Z"
    }
   },
   "execution_count": 142
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_test = test_fixed_title.drop(['tconst',  'label'], axis=1).values\n",
    "y_test = test_fixed_title.loc[:, 'label'].values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T20:13:14.273441Z",
     "start_time": "2024-03-10T20:13:14.269379Z"
    }
   },
   "execution_count": 143
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "RandomForest best parameters: {'classifier__max_depth': 10, 'classifier__n_estimators': 150}\n",
      "RandomForest best score: 0.7247\n",
      "Accuracy: 81.45% 80.55%\n",
      "Confusion Matrix:\n",
      "[[3478  491]\n",
      " [ 985 3005]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.78      0.88      0.82      3969\n",
      "        True       0.86      0.75      0.80      3990\n",
      "\n",
      "    accuracy                           0.81      7959\n",
      "   macro avg       0.82      0.81      0.81      7959\n",
      "weighted avg       0.82      0.81      0.81      7959\n",
      "\n",
      "0.5013262599469496 0.5013192612137203 0.43925116220630733 0.41210108169594517\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing pipeline\n",
    "preprocessing = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "# Base model pipelines\n",
    "models = {\n",
    "    'RandomForest': Pipeline(steps=[('preprocessing', preprocessing), ('classifier', RandomForestClassifier())])\n",
    "}\n",
    "\n",
    "hyperparameters = {\n",
    "    'RandomForest': {\n",
    "        'classifier__n_estimators': [50, 100, 150, 200],\n",
    "        'classifier__max_depth': [1, 3, 5, 7, 10],\n",
    "    }\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "for model_name, model_pipeline in models.items():\n",
    "    # Create a GridSearchCV object\n",
    "    grid_search = GridSearchCV(model_pipeline, hyperparameters[model_name], cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "    # Fit the model\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Store the best model\n",
    "    best_models[model_name] = grid_search.best_estimator_\n",
    "\n",
    "    # Print the best parameters and the best score\n",
    "    print(f\"{model_name} best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"{model_name} best score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "    # Use the best estimator to make predictions\n",
    "    y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "    # Test if adjusting the threshold helps improve the accuracy (knowing dataset is balanced)\n",
    "    y_proba = grid_search.best_estimator_.predict_proba(X_test)[:,1]\n",
    "    threshold = np.median(y_proba)\n",
    "    y_pred_th = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    # Calculate and print the accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}% {accuracy_score(y_test, y_pred_th) * 100:.2f}%\")\n",
    "\n",
    "    # Print the confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "    # Print the classification report\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    print(\"Classification Report:\")\n",
    "    print(class_report)\n",
    "\n",
    "    # See how balanced the predictions are\n",
    "    print (y_train.mean(), y_test.mean(), y_pred.mean(), threshold)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T20:13:25.050332Z",
     "start_time": "2024-03-10T20:13:18.545492Z"
    }
   },
   "execution_count": 144
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

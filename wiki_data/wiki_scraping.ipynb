{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import wikipediaapi\n",
    "wiki_wiki = wikipediaapi.Wikipedia('BigData', 'en')\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def search_wiki_page_key(title, year):\n",
    "    \n",
    "    # Search wikipedia for the URL\n",
    "    \n",
    "    language_code = 'en'\n",
    "    search_query = f'{title} film {year}'\n",
    "    headers = {\n",
    "    # 'Authorization': 'Bearer YOUR_ACCESS_TOKEN',\n",
    "    'User-Agent': 'BigDataScraper (randomemail@gmail.com)'\n",
    "    }\n",
    "\n",
    "    base_url = 'https://api.wikimedia.org/core/v1/wikipedia/'\n",
    "    endpoint = '/search/page'\n",
    "    url = base_url + language_code + endpoint\n",
    "    parameters = {'q': search_query, 'limit': 1}\n",
    "    response = requests.get(url, headers=headers, params=parameters)\n",
    "    \n",
    "    # API limit of 500 per hour\n",
    "    if response.status_code == 429:\n",
    "        print ('Sleeping for 10 mins')\n",
    "        \n",
    "        # This is in loop so ctrl+c can be used to interrupt the sleep\n",
    "        for i in range(10*60):\n",
    "            time.sleep(1)\n",
    "        \n",
    "        response = requests.get(url, headers=headers, params=parameters)\n",
    "    \n",
    "    try:\n",
    "        page_key = response.json()['pages'][0]['key']\n",
    "        return page_key\n",
    "    except (IndexError,KeyError):\n",
    "        return None       \n",
    "    \n",
    "\n",
    "def get_wiki_categories(wiki_page_key):\n",
    "    \n",
    "    wiki_page = wiki_wiki.page(wiki_page_key)\n",
    "    categories = [cat for cat in wiki_page.categories]\n",
    "    \n",
    "    return categories\n",
    "\n",
    "def get_infobox(wiki_page_key):\n",
    "    \n",
    "    url = f'https://en.wikipedia.org/wiki/{wiki_page_key}'\n",
    "    \n",
    "    # Fetch the content from the URL\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Find the infobox within the page\n",
    "    infobox = soup.find('table', {'class': 'infobox'})\n",
    "    if not infobox:\n",
    "        return None\n",
    "    \n",
    "    # Dictionary to store the information\n",
    "    infobox_data = {}\n",
    "    \n",
    "    # Iterate through each row in the infobox\n",
    "    for tr in infobox.find_all('tr'):\n",
    "        if tr.find('th') and tr.find('td'):\n",
    "            # Get the key from the header and the value from the data cell\n",
    "            key = tr.find('th').text.strip()\n",
    "            value = tr.find('td').text.strip()\n",
    "            \n",
    "            # Add the key-value pair to the dictionary\n",
    "            infobox_data[key] = value\n",
    "            \n",
    "    return infobox_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise DuckDB\n",
    "\n",
    "import duckdb\n",
    "\n",
    "# Path to store DuckDB with wiki data\n",
    "con_disk = duckdb.connect(database='wiki_data.duckdb')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>pTitle</th>\n",
       "      <th>oTitle</th>\n",
       "      <th>Year</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>numVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0003740</td>\n",
       "      <td>cabiria</td>\n",
       "      <td>None</td>\n",
       "      <td>1914</td>\n",
       "      <td>148</td>\n",
       "      <td>3452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0008663</td>\n",
       "      <td>a man there was</td>\n",
       "      <td>terje vigen</td>\n",
       "      <td>1917</td>\n",
       "      <td>65</td>\n",
       "      <td>1882.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0009369</td>\n",
       "      <td>mickey</td>\n",
       "      <td>mickey</td>\n",
       "      <td>1918</td>\n",
       "      <td>93</td>\n",
       "      <td>1119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0010307</td>\n",
       "      <td>jaccuse</td>\n",
       "      <td>None</td>\n",
       "      <td>1919</td>\n",
       "      <td>166</td>\n",
       "      <td>1692.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0010600</td>\n",
       "      <td>the doll</td>\n",
       "      <td>die puppe</td>\n",
       "      <td>1919</td>\n",
       "      <td>66</td>\n",
       "      <td>1898.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>tt9766294</td>\n",
       "      <td>fauji calling</td>\n",
       "      <td>fauji calling</td>\n",
       "      <td>2021</td>\n",
       "      <td>134</td>\n",
       "      <td>2921.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>tt9769668</td>\n",
       "      <td>tughlaq durbar</td>\n",
       "      <td>tughlaq durbar</td>\n",
       "      <td>2021</td>\n",
       "      <td>145</td>\n",
       "      <td>1430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>tt9784798</td>\n",
       "      <td>judas and the black messiah</td>\n",
       "      <td>judas and the black messiah</td>\n",
       "      <td>2021</td>\n",
       "      <td>126</td>\n",
       "      <td>65194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>tt9808510</td>\n",
       "      <td>vellam</td>\n",
       "      <td>vellam</td>\n",
       "      <td>2021</td>\n",
       "      <td>154</td>\n",
       "      <td>1731.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>tt9849004</td>\n",
       "      <td>happily</td>\n",
       "      <td>happily</td>\n",
       "      <td>2021</td>\n",
       "      <td>96</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tconst                       pTitle                       oTitle  \\\n",
       "0     tt0003740                      cabiria                         None   \n",
       "1     tt0008663              a man there was                  terje vigen   \n",
       "2     tt0009369                       mickey                       mickey   \n",
       "3     tt0010307                      jaccuse                         None   \n",
       "4     tt0010600                     the doll                    die puppe   \n",
       "...         ...                          ...                          ...   \n",
       "9995  tt9766294                fauji calling                fauji calling   \n",
       "9996  tt9769668               tughlaq durbar               tughlaq durbar   \n",
       "9997  tt9784798  judas and the black messiah  judas and the black messiah   \n",
       "9998  tt9808510                       vellam                       vellam   \n",
       "9999  tt9849004                      happily                      happily   \n",
       "\n",
       "      Year runtimeMinutes  numVotes  \n",
       "0     1914            148    3452.0  \n",
       "1     1917             65    1882.0  \n",
       "2     1918             93    1119.0  \n",
       "3     1919            166    1692.0  \n",
       "4     1919             66    1898.0  \n",
       "...    ...            ...       ...  \n",
       "9995  2021            134    2921.0  \n",
       "9996  2021            145    1430.0  \n",
       "9997  2021            126   65194.0  \n",
       "9998  2021            154    1731.0  \n",
       "9999  2021             96       NaN  \n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load all the movie data from training, validation and test sets\n",
    "\n",
    "con_mem = duckdb.connect(database=':memory:')\n",
    "film_df = con_mem.execute('''\n",
    "    SELECT tconst,\n",
    "        REGEXP_REPLACE(TRANSLATE(LOWER(TRIM(primaryTitle)), 'áàãäåæßçéèêíîïñòóôöøớúûüý','aaaaaabceeeiiinoooooouuuy'),'[^a-zA-Z0-9 ]','','g') AS pTitle,\n",
    "        REGEXP_REPLACE(TRANSLATE(LOWER(TRIM(originalTitle)), 'áàãäåæßçéèêíîïñòóôöøớúûüý','aaaaaabceeeiiinoooooouuuy'),'[^a-zA-Z0-9 ]','','g') AS oTitle,\n",
    "        CASE\n",
    "            WHEN startYear LIKE '%N%' THEN endYear\n",
    "            ELSE startYear\n",
    "        END AS Year,\n",
    "        runtimeMinutes,numVotes\n",
    "    FROM 'big-data-course-2024-projects/imdb/train-[1-8].csv'\n",
    "    UNION\n",
    "    SELECT tconst,\n",
    "        REGEXP_REPLACE(TRANSLATE(LOWER(TRIM(primaryTitle)), 'áàãäåæßçéèêíîïñòóôöøớúûüý','aaaaaabceeeiiinoooooouuuy'),'[^a-zA-Z0-9 ]','','g') AS pTitle,\n",
    "        REGEXP_REPLACE(TRANSLATE(LOWER(TRIM(originalTitle)), 'áàãäåæßçéèêíîïñòóôöøớúûüý','aaaaaabceeeiiinoooooouuuy'),'[^a-zA-Z0-9 ]','','g') AS oTitle,\n",
    "        CASE\n",
    "            WHEN startYear LIKE '%N%' THEN endYear\n",
    "            ELSE startYear\n",
    "        END AS Year,\n",
    "        runtimeMinutes,numVotes\n",
    "    FROM 'big-data-course-2024-projects/imdb/test_hidden.csv'\n",
    "    UNION\n",
    "    SELECT tconst,\n",
    "        REGEXP_REPLACE(TRANSLATE(LOWER(TRIM(primaryTitle)), 'áàãäåæßçéèêíîïñòóôöøớúûüý','aaaaaabceeeiiinoooooouuuy'),'[^a-zA-Z0-9 ]','','g') AS pTitle,\n",
    "        REGEXP_REPLACE(TRANSLATE(LOWER(TRIM(originalTitle)), 'áàãäåæßçéèêíîïñòóôöøớúûüý','aaaaaabceeeiiinoooooouuuy'),'[^a-zA-Z0-9 ]','','g') AS oTitle,\n",
    "        CASE\n",
    "            WHEN startYear LIKE '%N%' THEN endYear\n",
    "            ELSE startYear\n",
    "        END AS Year,\n",
    "        runtimeMinutes,numVotes\n",
    "    FROM 'big-data-course-2024-projects/imdb/validation_hidden.csv'\n",
    "    ORDER BY Year, tconst\n",
    "''').df()\n",
    "\n",
    "film_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = []\n",
    "\n",
    "for idx, film in film_df.iterrows():\n",
    "    \n",
    "    tconst = film['tconst']\n",
    "    title = film['pTitle']\n",
    "    year = film['Year']\n",
    "    \n",
    "    # Check if entry exists in database\n",
    "    tconst_exists = con_disk.execute(f'''\n",
    "        SELECT EXISTS (SELECT 1 FROM raw_wiki WHERE tconst = '{tconst}')\n",
    "    ''').fetchone()[0]\n",
    "    \n",
    "    # Skip if it exists already\n",
    "    if tconst_exists:            \n",
    "        continue\n",
    "    \n",
    "    # Scrape wikipedia data\n",
    "    wiki_key = search_wiki_page_key(title, year)\n",
    "    \n",
    "    if wiki_key is None:\n",
    "        print (idx, tconst, title, year, '--key could not be found--')\n",
    "        continue\n",
    "        \n",
    "    film_categories = get_wiki_categories(wiki_key)\n",
    "    infobox_data = get_infobox(wiki_key)\n",
    "    \n",
    "    # Check that info box corresponds to a film\n",
    "    \n",
    "    # Append to film\n",
    "    film['wiki_key'] = wiki_key\n",
    "    \n",
    "    if infobox_data is None:\n",
    "        film['categories'] = None\n",
    "        film['infobox'] = None\n",
    "    \n",
    "    elif 'Directed by' in infobox_data.keys():\n",
    "        film['categories'] = json.dumps(film_categories)\n",
    "        film['infobox'] = json.dumps(infobox_data)\n",
    "    else:\n",
    "        film['categories'] = None\n",
    "        film['infobox'] = None\n",
    "    \n",
    "    filmT = film.to_frame().T\n",
    "    filmT = filmT.drop(columns='oTitle')\n",
    "    \n",
    "    # Save to database\n",
    "    con_disk.execute(\"INSERT INTO raw_wiki SELECT * FROM filmT;\")\n",
    "    # break\n",
    "    # Track progress\n",
    "    print (idx, tconst, title, film['oTitle'], year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_disk.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

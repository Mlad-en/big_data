{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x284d24a2f70>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import duckdb\n",
    "\n",
    "# some DuckDB setup\n",
    "con = duckdb.connect(database=':memory:')\n",
    "# enable automatic query parallelization\n",
    "con.execute(\"PRAGMA threads=2\")\n",
    "# enable caching of parquet metadata\n",
    "con.execute(\"PRAGMA enable_object_cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>pTitle</th>\n",
       "      <th>oTitle</th>\n",
       "      <th>ForeignFilm</th>\n",
       "      <th>n_words</th>\n",
       "      <th>Year</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>numVotes</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0010600</td>\n",
       "      <td>the doll</td>\n",
       "      <td>die puppe</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1919</td>\n",
       "      <td>66</td>\n",
       "      <td>1898.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0011841</td>\n",
       "      <td>way down east</td>\n",
       "      <td>way down east</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1920</td>\n",
       "      <td>145</td>\n",
       "      <td>5376.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0012494</td>\n",
       "      <td>destiny</td>\n",
       "      <td>der mude tod</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1921</td>\n",
       "      <td>97</td>\n",
       "      <td>5842.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0015163</td>\n",
       "      <td>the navigator</td>\n",
       "      <td>the navigator</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1924</td>\n",
       "      <td>59</td>\n",
       "      <td>9652.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0016220</td>\n",
       "      <td>the phantom of the opera</td>\n",
       "      <td>the phantom of the opera</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1925</td>\n",
       "      <td>93</td>\n",
       "      <td>17887.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7954</th>\n",
       "      <td>tt9625664</td>\n",
       "      <td>trauma center</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "      <td>87</td>\n",
       "      <td>12951.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7955</th>\n",
       "      <td>tt9741310</td>\n",
       "      <td>slaxx</td>\n",
       "      <td>slaxx</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>77</td>\n",
       "      <td>2464.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7956</th>\n",
       "      <td>tt9742392</td>\n",
       "      <td>kindred</td>\n",
       "      <td>kindred</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>101</td>\n",
       "      <td>1719.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7957</th>\n",
       "      <td>tt9850386</td>\n",
       "      <td>the bee gees how can you mend a broken heart</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2020</td>\n",
       "      <td>111</td>\n",
       "      <td>4144.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7958</th>\n",
       "      <td>tt9911196</td>\n",
       "      <td>the marriage escape</td>\n",
       "      <td>de beentjes van sinthildegard</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>103</td>\n",
       "      <td>3242.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7959 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tconst                                        pTitle  \\\n",
       "0     tt0010600                                      the doll   \n",
       "1     tt0011841                                 way down east   \n",
       "2     tt0012494                                       destiny   \n",
       "3     tt0015163                                 the navigator   \n",
       "4     tt0016220                      the phantom of the opera   \n",
       "...         ...                                           ...   \n",
       "7954  tt9625664                                 trauma center   \n",
       "7955  tt9741310                                         slaxx   \n",
       "7956  tt9742392                                       kindred   \n",
       "7957  tt9850386  the bee gees how can you mend a broken heart   \n",
       "7958  tt9911196                           the marriage escape   \n",
       "\n",
       "                             oTitle  ForeignFilm  n_words  Year  \\\n",
       "0                         die puppe            1        2  1919   \n",
       "1                     way down east            1        3  1920   \n",
       "2                      der mude tod            1        1  1921   \n",
       "3                     the navigator            1        2  1924   \n",
       "4          the phantom of the opera            1        5  1925   \n",
       "...                             ...          ...      ...   ...   \n",
       "7954                           None            0        2  2019   \n",
       "7955                          slaxx            1        1  2020   \n",
       "7956                        kindred            1        1  2020   \n",
       "7957                           None            0       10  2020   \n",
       "7958  de beentjes van sinthildegard            1        3  2020   \n",
       "\n",
       "     runtimeMinutes  numVotes  label  \n",
       "0                66    1898.0      1  \n",
       "1               145    5376.0      1  \n",
       "2                97    5842.0      1  \n",
       "3                59    9652.0      1  \n",
       "4                93   17887.0      1  \n",
       "...             ...       ...    ...  \n",
       "7954             87   12951.0      0  \n",
       "7955             77    2464.0      0  \n",
       "7956            101    1719.0      0  \n",
       "7957            111    4144.0      1  \n",
       "7958            103    3242.0      1  \n",
       "\n",
       "[7959 rows x 9 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load all the data into the duck database\n",
    "all_training_data = con.execute('''\n",
    "    SELECT \n",
    "        tconst,\n",
    "        \n",
    "        -- Clean up the movie title text. Remove excess whitespace, convert to lowercase, convert non-ascii to ascii equivalent, \n",
    "        -- remove everything that is non-alpanumeric or a space.\n",
    "        REGEXP_REPLACE(TRANSLATE(LOWER(TRIM(primaryTitle)), 'áàãäåæßçéèêíîïñòóôöøớúûüý','aaaaaabceeeiiinoooooouuuy'),'[^a-zA-Z0-9 ]','','g') AS pTitle,\n",
    "        REGEXP_REPLACE(TRANSLATE(LOWER(TRIM(originalTitle)),'áàãäåæßçéèêíîïñòóôöøớúûüý','aaaaaabceeeiiinoooooouuuy'),'[^a-zA-Z0-9 ]','','g') AS oTitle,\n",
    "        \n",
    "        -- Flag for indicating foreign film\n",
    "        CASE\n",
    "           WHEN oTitle IS NULL THEN 0\n",
    "           ELSE 1\n",
    "        END AS ForeignFilm,\n",
    "        \n",
    "        -- Count number of words in title\n",
    "        LENGTH(pTitle) - LENGTH(REPLACE(pTitle, ' ', '')) + 1 AS n_words,\n",
    "        \n",
    "        -- Merge start year and end year into single column\n",
    "        CASE\n",
    "            WHEN startYear LIKE '%N%' THEN endYear\n",
    "            ELSE startYear\n",
    "        END AS Year,\n",
    "        runtimeMinutes,\n",
    "        numVotes,\n",
    "        \n",
    "        -- Convert True/False to 1/0\n",
    "        CAST(label AS INT) as label\n",
    "    FROM 'big-data-course-2024-projects/imdb/train-[1-8].csv'\n",
    "''').df()\n",
    "\n",
    "# Replace empty (\\N) with nans\n",
    "all_training_data = all_training_data.replace('\\\\N', np.nan)\n",
    "\n",
    "all_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0003740</td>\n",
       "      <td>1914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0008663</td>\n",
       "      <td>1917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0009369</td>\n",
       "      <td>1918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0010307</td>\n",
       "      <td>1919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0010600</td>\n",
       "      <td>1919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>tt9766294</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>tt9769668</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>tt9784798</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>tt9808510</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>tt9849004</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tconst  Year\n",
       "0     tt0003740  1914\n",
       "1     tt0008663  1917\n",
       "2     tt0009369  1918\n",
       "3     tt0010307  1919\n",
       "4     tt0010600  1919\n",
       "...         ...   ...\n",
       "9995  tt9766294  2021\n",
       "9996  tt9769668  2021\n",
       "9997  tt9784798  2021\n",
       "9998  tt9808510  2021\n",
       "9999  tt9849004  2021\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load json files and drop empty rows\n",
    "directors = pd.read_json('big-data-course-2024-projects/imdb/directing.json').replace('\\\\N', np.nan).dropna()\n",
    "writers = pd.read_json('big-data-course-2024-projects/imdb/writing.json').replace('\\\\N', np.nan).dropna()\n",
    "\n",
    "# Combine all films listed in the writer/director files with the year of the film \n",
    "# (from training, validation and test data).\n",
    "movie_year = con.execute('''\n",
    "    SELECT tconst,\n",
    "        CASE\n",
    "            WHEN startYear LIKE '%N%' THEN endYear\n",
    "            ELSE startYear\n",
    "        END AS Year,\n",
    "    FROM 'big-data-course-2024-projects/imdb/train-[1-8].csv'\n",
    "    UNION\n",
    "    SELECT tconst,\n",
    "        CASE\n",
    "            WHEN startYear LIKE '%N%' THEN endYear\n",
    "            ELSE startYear\n",
    "        END AS Year,\n",
    "    FROM 'big-data-course-2024-projects/imdb/test_hidden.csv'\n",
    "    UNION\n",
    "    SELECT tconst,\n",
    "        CASE\n",
    "            WHEN startYear LIKE '%N%' THEN endYear\n",
    "            ELSE startYear\n",
    "        END AS Year,\n",
    "    FROM 'big-data-course-2024-projects/imdb/validation_hidden.csv'\n",
    "    ORDER BY Year, tconst\n",
    "''').df()\n",
    "\n",
    "movie_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>Year</th>\n",
       "      <th>writer</th>\n",
       "      <th>director</th>\n",
       "      <th>writer_experience</th>\n",
       "      <th>director_experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0003740</td>\n",
       "      <td>1914</td>\n",
       "      <td>nm0515385</td>\n",
       "      <td>nm0665163</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0003740</td>\n",
       "      <td>1914</td>\n",
       "      <td>nm0758215</td>\n",
       "      <td>nm0665163</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0003740</td>\n",
       "      <td>1914</td>\n",
       "      <td>nm0665163</td>\n",
       "      <td>nm0665163</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0003740</td>\n",
       "      <td>1914</td>\n",
       "      <td>nm0195339</td>\n",
       "      <td>nm0665163</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0008663</td>\n",
       "      <td>1917</td>\n",
       "      <td>nm0803705</td>\n",
       "      <td>nm0803705</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27883</th>\n",
       "      <td>tt9784798</td>\n",
       "      <td>2021</td>\n",
       "      <td>nm3584219</td>\n",
       "      <td>nm3489851</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27884</th>\n",
       "      <td>tt9808510</td>\n",
       "      <td>2021</td>\n",
       "      <td>nm8904180</td>\n",
       "      <td>nm8904180</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27885</th>\n",
       "      <td>tt9808510</td>\n",
       "      <td>2021</td>\n",
       "      <td>nm10260663</td>\n",
       "      <td>nm8904180</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27886</th>\n",
       "      <td>tt9808510</td>\n",
       "      <td>2021</td>\n",
       "      <td>nm9925241</td>\n",
       "      <td>nm8904180</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27887</th>\n",
       "      <td>tt9849004</td>\n",
       "      <td>2021</td>\n",
       "      <td>nm2818863</td>\n",
       "      <td>nm2818863</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27888 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          tconst  Year      writer   director  writer_experience  \\\n",
       "0      tt0003740  1914   nm0515385  nm0665163                  1   \n",
       "1      tt0003740  1914   nm0758215  nm0665163                  1   \n",
       "2      tt0003740  1914   nm0665163  nm0665163                  1   \n",
       "3      tt0003740  1914   nm0195339  nm0665163                  1   \n",
       "4      tt0008663  1917   nm0803705  nm0803705                  1   \n",
       "...          ...   ...         ...        ...                ...   \n",
       "27883  tt9784798  2021   nm3584219  nm3489851                  1   \n",
       "27884  tt9808510  2021   nm8904180  nm8904180                  1   \n",
       "27885  tt9808510  2021  nm10260663  nm8904180                  1   \n",
       "27886  tt9808510  2021   nm9925241  nm8904180                  1   \n",
       "27887  tt9849004  2021   nm2818863  nm2818863                  2   \n",
       "\n",
       "       director_experience  \n",
       "0                        1  \n",
       "1                        1  \n",
       "2                        1  \n",
       "3                        1  \n",
       "4                        1  \n",
       "...                    ...  \n",
       "27883                    1  \n",
       "27884                    1  \n",
       "27885                    1  \n",
       "27886                    1  \n",
       "27887                    1  \n",
       "\n",
       "[27888 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the number of films worked on previously by the writers and directors\n",
    "# Includes the current film\n",
    "\n",
    "experience = con.execute('''\n",
    "    SELECT tconst, Year, writer, director,\n",
    "    COUNT(DISTINCT tconst) OVER(PARTITION BY writer ORDER BY Year, tconst) AS writer_experience,\n",
    "    COUNT(DISTINCT tconst) OVER(PARTITION BY director ORDER BY Year, tconst) AS director_experience,\n",
    "    FROM movie_year my\n",
    "    LEFT JOIN writers ON writers.movie == my.tconst\n",
    "    LEFT JOIN directors ON directors.movie == my.tconst\n",
    "    ORDER BY Year, tconst\n",
    "''').df()\n",
    "\n",
    "experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>Year</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>ForeignFilm</th>\n",
       "      <th>n_words</th>\n",
       "      <th>numVotes</th>\n",
       "      <th>n_writers</th>\n",
       "      <th>avgexp_writers</th>\n",
       "      <th>totexp_writers</th>\n",
       "      <th>n_directors</th>\n",
       "      <th>avgexp_directors</th>\n",
       "      <th>totexp_directors</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0009369</td>\n",
       "      <td>1918</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1119.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0011439</td>\n",
       "      <td>1920</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2439.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0011841</td>\n",
       "      <td>1920</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5376.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0012532</td>\n",
       "      <td>1921</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0127834</td>\n",
       "      <td>1921</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7954</th>\n",
       "      <td>tt5420210</td>\n",
       "      <td>2020</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5737.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7955</th>\n",
       "      <td>tt6627168</td>\n",
       "      <td>2020</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1411.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7956</th>\n",
       "      <td>tt11307814</td>\n",
       "      <td>2021</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12409.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7957</th>\n",
       "      <td>tt4532038</td>\n",
       "      <td>2020</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>18446.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7958</th>\n",
       "      <td>tt4940336</td>\n",
       "      <td>2021</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1703.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7959 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          tconst  Year runtimeMinutes  ForeignFilm  n_words  numVotes  \\\n",
       "0      tt0009369  1918             93            1        1    1119.0   \n",
       "1      tt0011439  1920             79            1        4    2439.0   \n",
       "2      tt0011841  1920            145            1        3    5376.0   \n",
       "3      tt0012532  1921            150            0        4       NaN   \n",
       "4      tt0127834  1921             62            0        4    1213.0   \n",
       "...          ...   ...            ...          ...      ...       ...   \n",
       "7954   tt5420210  2020            104            0        3    5737.0   \n",
       "7955   tt6627168  2020             73            1        1    1411.0   \n",
       "7956  tt11307814  2021             86            1        2   12409.0   \n",
       "7957   tt4532038  2020             94            1        4   18446.0   \n",
       "7958   tt4940336  2021            109            0        1    1703.0   \n",
       "\n",
       "      n_writers  avgexp_writers  totexp_writers  n_directors  \\\n",
       "0             2        1.000000             1.0            2   \n",
       "1             3        1.000000             1.0            1   \n",
       "2             5        1.000000             1.0            1   \n",
       "3             3        1.500000             3.0            1   \n",
       "4             1        1.000000             1.0            1   \n",
       "...         ...             ...             ...          ...   \n",
       "7954          3        2.666667             8.0            1   \n",
       "7955          3        1.000000             1.0            1   \n",
       "7956          2        1.500000             3.0            1   \n",
       "7957          3        1.500000             3.0            1   \n",
       "7958          1        1.000000             1.0            1   \n",
       "\n",
       "      avgexp_directors  totexp_directors  label  \n",
       "0                  1.0               1.0      0  \n",
       "1                  1.0               1.0      1  \n",
       "2                  1.0               1.0      1  \n",
       "3                  2.0               2.0      1  \n",
       "4                  1.0               1.0      1  \n",
       "...                ...               ...    ...  \n",
       "7954               3.0               3.0      0  \n",
       "7955               1.0               1.0      1  \n",
       "7956               2.0               2.0      0  \n",
       "7957               4.0               4.0      0  \n",
       "7958               1.0               1.0      0  \n",
       "\n",
       "[7959 rows x 13 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge movie data with the experience level of the writers and directors.\n",
    "# For each film, calculate the number of writers/directors, average experience and total experience\n",
    "\n",
    "data_experience = con.execute('''\n",
    "    SELECT \n",
    "      ANY_VALUE(td.tconst) AS tconst, \n",
    "      ANY_VALUE(td.Year) AS Year, \n",
    "      ANY_VALUE(runtimeMinutes) AS runtimeMinutes,\n",
    "      ANY_VALUE(ForeignFilm) AS ForeignFilm, \n",
    "      ANY_VALUE(n_words) AS n_words, \n",
    "      ANY_VALUE(numVotes) AS numVotes,\n",
    "      COUNT(DISTINCT writer) AS n_writers,\n",
    "      AVG(DISTINCT e.writer_experience) AS avgexp_writers,\n",
    "      SUM(DISTINCT e.writer_experience) AS totexp_writers,\n",
    "      COUNT(DISTINCT director) AS n_directors,\n",
    "      AVG(DISTINCT e.director_experience) AS avgexp_directors,\n",
    "      SUM(DISTINCT e.director_experience) AS totexp_directors,\n",
    "      ANY_VALUE(label) AS label\n",
    "    FROM all_training_data td\n",
    "    LEFT JOIN experience e ON e.tconst == td.tconst\n",
    "    GROUP BY td.tconst\n",
    "''').df()\n",
    "\n",
    "data_experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split training data in train and test split\n",
    "\n",
    "X = data_experience.drop(columns=['label'])\n",
    "y = data_experience['label']\n",
    "\n",
    "# Small test size because cross-validation (and want to train on more data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "LogisticRegression best parameters: {'classifier__C': 10}\n",
      "LogisticRegression best score: 0.7254\n",
      "Accuracy: 71.86% 72.74%\n",
      "Confusion Matrix:\n",
      "[[310  87]\n",
      " [137 262]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.78      0.73       397\n",
      "           1       0.75      0.66      0.70       399\n",
      "\n",
      "    accuracy                           0.72       796\n",
      "   macro avg       0.72      0.72      0.72       796\n",
      "weighted avg       0.72      0.72      0.72       796\n",
      "\n",
      "0.5013262599469496 0.5012562814070352 0.43844221105527637 0.443091041460555\n",
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "DecisionTree best parameters: {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}\n",
      "DecisionTree best score: 0.7361\n",
      "Accuracy: 72.36% 71.11%\n",
      "Confusion Matrix:\n",
      "[[324  73]\n",
      " [147 252]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.82      0.75       397\n",
      "           1       0.78      0.63      0.70       399\n",
      "\n",
      "    accuracy                           0.72       796\n",
      "   macro avg       0.73      0.72      0.72       796\n",
      "weighted avg       0.73      0.72      0.72       796\n",
      "\n",
      "0.5013262599469496 0.5012562814070352 0.4082914572864322 0.4144385026737968\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "RandomForest best parameters: {'classifier__max_depth': 10, 'classifier__n_estimators': 150}\n",
      "RandomForest best score: 0.7574\n",
      "Accuracy: 74.75% 74.75%\n",
      "Confusion Matrix:\n",
      "[[316  81]\n",
      " [120 279]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.80      0.76       397\n",
      "           1       0.78      0.70      0.74       399\n",
      "\n",
      "    accuracy                           0.75       796\n",
      "   macro avg       0.75      0.75      0.75       796\n",
      "weighted avg       0.75      0.75      0.75       796\n",
      "\n",
      "0.5013262599469496 0.5012562814070352 0.45226130653266333 0.43760804824317245\n",
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n",
      "XGBoost best parameters: {'classifier__learning_rate': 0.1, 'classifier__max_depth': 5, 'classifier__n_estimators': 100, 'classifier__subsample': 0.8}\n",
      "XGBoost best score: 0.7614\n",
      "Accuracy: 75.88% 75.75%\n",
      "Confusion Matrix:\n",
      "[[315  82]\n",
      " [110 289]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.79      0.77       397\n",
      "           1       0.78      0.72      0.75       399\n",
      "\n",
      "    accuracy                           0.76       796\n",
      "   macro avg       0.76      0.76      0.76       796\n",
      "weighted avg       0.76      0.76      0.76       796\n",
      "\n",
      "0.5013262599469496 0.5012562814070352 0.46608040201005024 0.45148438\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessing = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "# Base model pipelines\n",
    "models = {\n",
    "    'LogisticRegression': Pipeline(steps=[('preprocessing', preprocessing), ('classifier', LogisticRegression(max_iter=1000))]),\n",
    "    'DecisionTree': Pipeline(steps=[('preprocessing', preprocessing), ('classifier', DecisionTreeClassifier())]),\n",
    "    'RandomForest': Pipeline(steps=[('preprocessing', preprocessing), ('classifier', RandomForestClassifier())]),\n",
    "    'XGBoost': Pipeline(steps=[('preprocessing', preprocessing), ('classifier', xgb.XGBClassifier())])\n",
    "    \n",
    "}\n",
    "\n",
    "hyperparameters = {\n",
    "    'LogisticRegression': {\n",
    "        'classifier__C': [0.01, 0.1, 1, 10]\n",
    "    },\n",
    "    'DecisionTree': {\n",
    "        'classifier__max_depth': [None, 5, 10, 15, 20],\n",
    "        'classifier__min_samples_split': [2, 5, 10],\n",
    "        'classifier__min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'classifier__n_estimators': [50, 100, 150, 200],\n",
    "        'classifier__max_depth': [1, 3, 5, 7, 10],\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'classifier__n_estimators': [50, 100, 150, 200],\n",
    "        'classifier__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "        'classifier__max_depth': [2, 3, 4, 5],\n",
    "        'classifier__subsample': [0.8, 1.0]\n",
    "    }\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "for model_name, model_pipeline in models.items():\n",
    "    # Create a GridSearchCV object\n",
    "    grid_search = GridSearchCV(model_pipeline, hyperparameters[model_name], cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "    \n",
    "    # Fit the model\n",
    "    grid_search.fit(X_train.drop(columns=['tconst']), y_train)\n",
    "    \n",
    "    # Store the best model\n",
    "    best_models[model_name] = grid_search.best_estimator_\n",
    "    \n",
    "    # Print the best parameters and the best score\n",
    "    print(f\"{model_name} best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"{model_name} best score: {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    # Use the best estimator to make predictions\n",
    "    y_pred = grid_search.best_estimator_.predict(X_test.drop(columns=['tconst']))\n",
    "\n",
    "    # Test if adjusting the threshold helps improve the accuracy (knowing dataset is balanced)\n",
    "    y_proba = grid_search.best_estimator_.predict_proba(X_test.drop(columns=['tconst']))[:,1]\n",
    "    threshold = np.median(y_proba)\n",
    "    y_pred_th = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    # Calculate and print the accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}% {accuracy_score(y_test, y_pred_th) * 100:.2f}%\")\n",
    "\n",
    "    # Print the confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "    # Print the classification report\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    print(\"Classification Report:\")\n",
    "    print(class_report)\n",
    "\n",
    "    # See how balanced the predictions are\n",
    "    print (y_train.mean(), y_test.mean(), y_pred.mean(), threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load hidden validation and test sets and run through best performing prediction model\n",
    "# TODO: Tidy this bit up\n",
    "\n",
    "validation_data = con.execute('''\n",
    "    SELECT tconst,\n",
    "        REGEXP_REPLACE(TRANSLATE(LOWER(TRIM(primaryTitle)), 'áàãäåæßçéèêíîïñòóôöøớúûüý','aaaaaabceeeiiinoooooouuuy'),'[^a-zA-Z0-9 ]','','g') AS pTitle,\n",
    "        REGEXP_REPLACE(TRANSLATE(LOWER(TRIM(originalTitle)),'áàãäåæßçéèêíîïñòóôöøớúûüý','aaaaaabceeeiiinoooooouuuy'),'[^a-zA-Z0-9 ]','','g') AS oTitle,\n",
    "        CASE\n",
    "           WHEN oTitle IS NULL THEN 0\n",
    "           ELSE 1\n",
    "        END AS ForeignFilm,\n",
    "        LENGTH(pTitle) - LENGTH(REPLACE(pTitle, ' ', '')) + 1 AS n_words,\n",
    "        CASE\n",
    "            WHEN startYear LIKE '%N%' THEN endYear\n",
    "            ELSE startYear\n",
    "        END AS Year,\n",
    "        runtimeMinutes,\n",
    "        numVotes\n",
    "        FROM 'big-data-course-2024-projects/imdb/validation_hidden.csv'\n",
    "    ''').df().replace('\\\\N',np.nan)\n",
    "\n",
    "test_data = con.execute('''\n",
    "    SELECT tconst,\n",
    "        REGEXP_REPLACE(TRANSLATE(LOWER(TRIM(primaryTitle)), 'áàãäåæßçéèêíîïñòóôöøớúûüý','aaaaaabceeeiiinoooooouuuy'),'[^a-zA-Z0-9 ]','','g') AS pTitle,\n",
    "        REGEXP_REPLACE(TRANSLATE(LOWER(TRIM(originalTitle)),'áàãäåæßçéèêíîïñòóôöøớúûüý','aaaaaabceeeiiinoooooouuuy'),'[^a-zA-Z0-9 ]','','g') AS oTitle,\n",
    "        CASE\n",
    "           WHEN oTitle IS NULL THEN 0\n",
    "           ELSE 1\n",
    "        END AS ForeignFilm,\n",
    "        LENGTH(pTitle) - LENGTH(REPLACE(pTitle, ' ', '')) + 1 AS n_words,\n",
    "        CASE\n",
    "            WHEN startYear LIKE '%N%' THEN endYear\n",
    "            ELSE startYear\n",
    "        END AS Year,\n",
    "        runtimeMinutes,\n",
    "        numVotes\n",
    "        FROM 'big-data-course-2024-projects/imdb/test_hidden.csv'\n",
    "    ''').df().replace('\\\\N',np.nan)\n",
    "\n",
    "hidden_validation_data = con.execute('''\n",
    "    SELECT\n",
    "      ANY_VALUE(td.tconst) AS tconst,\n",
    "      ANY_VALUE(td.Year) AS Year, \n",
    "      ANY_VALUE(runtimeMinutes) AS runtimeMinutes,\n",
    "      ANY_VALUE(ForeignFilm) AS ForeignFilm, \n",
    "      ANY_VALUE(n_words) AS n_words, \n",
    "      ANY_VALUE(numVotes) AS numVotes,\n",
    "      COUNT(DISTINCT writer) AS n_writers,\n",
    "      AVG(DISTINCT e.writer_experience) AS avgexp_writers,\n",
    "      SUM(DISTINCT e.writer_experience) AS totexp_writers,\n",
    "      COUNT(DISTINCT director) AS n_directors,\n",
    "      AVG(DISTINCT e.director_experience) AS avgexp_directors,\n",
    "      SUM(DISTINCT e.director_experience) AS totexp_directors\n",
    "    FROM validation_data td\n",
    "    LEFT JOIN experience e ON e.tconst == td.tconst\n",
    "    GROUP BY td.tconst\n",
    "    ORDER BY td.tconst\n",
    "''').df()\n",
    "\n",
    "hidden_test_data = con.execute('''\n",
    "    SELECT\n",
    "      ANY_VALUE(td.tconst) AS tconst, \n",
    "      ANY_VALUE(td.Year) AS Year, \n",
    "      ANY_VALUE(runtimeMinutes) AS runtimeMinutes,\n",
    "      ANY_VALUE(ForeignFilm) AS ForeignFilm, \n",
    "      ANY_VALUE(n_words) AS n_words, \n",
    "      ANY_VALUE(numVotes) AS numVotes,\n",
    "      COUNT(DISTINCT writer) AS n_writers,\n",
    "      AVG(DISTINCT e.writer_experience) AS avgexp_writers,\n",
    "      SUM(DISTINCT e.writer_experience) AS totexp_writers,\n",
    "      COUNT(DISTINCT director) AS n_directors,\n",
    "      AVG(DISTINCT e.director_experience) AS avgexp_directors,\n",
    "      SUM(DISTINCT e.director_experience) AS totexp_directors\n",
    "    FROM test_data td\n",
    "    LEFT JOIN experience e ON e.tconst == td.tconst\n",
    "    GROUP BY td.tconst\n",
    "    ORDER BY td.tconst\n",
    "''').df()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41465968586387436 0.44659300184162065\n"
     ]
    }
   ],
   "source": [
    "# Choose best performing model\n",
    "\n",
    "valid_pred = best_models['RandomForest'].predict(hidden_validation_data.drop(columns=['tconst']))\n",
    "test_pred = best_models['RandomForest'].predict(hidden_test_data.drop(columns=['tconst']))\n",
    "\n",
    "print (valid_pred.mean(), test_pred.mean())\n",
    "\n",
    "# Add predicted column\n",
    "hidden_validation_data['pred_label'] = valid_pred\n",
    "hidden_test_data['pred_label'] = test_pred\n",
    "\n",
    "# Save to test file for prediction upload\n",
    "np.savetxt('valid_predictions.txt', np.where(valid_pred == 1, 'True', 'False'), fmt='%s', newline='\\n')\n",
    "np.savetxt('test_predictions.txt', np.where(test_pred == 1, 'True', 'False'), fmt='%s', newline='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True\n"
     ]
    }
   ],
   "source": [
    "# Validate that the labels match up with the correct movie title (in case order has been messed around)\n",
    "\n",
    "df_valid = pd.read_csv('big-data-course-2024-projects/imdb/validation_hidden.csv')\n",
    "df_test = pd.read_csv('big-data-course-2024-projects/imdb/test_hidden.csv')\n",
    "\n",
    "print ((df_valid['tconst'] == hidden_validation_data['tconst']).all(),\n",
    "       (df_test['tconst'] == hidden_test_data['tconst']).all())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
